{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Model - Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nbnj55g63joG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ss2wk3e3joK"
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "##########                DATABASE FUNCTIONS                     #############\n",
    "##############################################################################\n",
    "#### Read function to import data from the SQL to a pandas dataframe.\n",
    "def readSQL(query):\n",
    "    import pandas as pd\n",
    "    import sqlite3 as sql3\n",
    "    db = sql3.connect(DB_FILE)\n",
    "    df = pd.read_sql_query(query, db)\n",
    "    db.close()\n",
    "    return(df)\n",
    "\n",
    "#### Write a pandas dataframe into an SQL table. Use overwrite=True if you want to delete \n",
    "#### first a pre-existent table with the same name. Use append=True if you want to append\n",
    "#### the data in the dataframe to a pre-existent table.\n",
    "def writeSQL(df,tablename,overwrite=False, append=False):\n",
    "    import pandas as pd\n",
    "    import sqlite3 as sql\n",
    "    db = sql.connect(DB_FILE)\n",
    "    if (overwrite):\n",
    "        action = \"replace\"\n",
    "    elif (append):\n",
    "        action = \"append\"\n",
    "    else: \n",
    "        action = \"fail\"\n",
    "    df.to_sql(tablename, db, if_exists=action)\n",
    "    db.close()\n",
    "def listTables():\n",
    "    import sqlite3 as sql3\n",
    "    db = sql3.connect(DB_FILE)\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    res = cur.fetchall()\n",
    "    cur.close()\n",
    "    db.close()\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcO8umzK3joM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "DB_FILE = \"%s\\Data\\loans.db\" % cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1082
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 735,
     "status": "error",
     "timestamp": 1550917238885,
     "user": {
      "displayName": "Nadav Feldman",
      "photoUrl": "",
      "userId": "13972438119586701104"
     },
     "user_tz": -120
    },
    "id": "BbmMqpmM3joP",
    "outputId": "1e827552-6f0b-40e8-9449-2833484644a8"
   },
   "outputs": [],
   "source": [
    "X_Train = readSQL('''SELECT * FROM X_train_scaled''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Q63Lm9c3joT"
   },
   "outputs": [],
   "source": [
    "Y_Train = readSQL('''SELECT * FROM Y_train''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = X_Train.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuhTbiT03joR"
   },
   "outputs": [],
   "source": [
    "Y_Train = Y_Train.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQzqFdkA3job"
   },
   "outputs": [],
   "source": [
    "X_Dev = readSQL('''SELECT * FROM X_dev_scaled''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Nim3i2r3joe"
   },
   "outputs": [],
   "source": [
    "X_Dev = X_Dev.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6jq7GUo3jog"
   },
   "outputs": [],
   "source": [
    "Y_Dev = readSQL('''SELECT * FROM Y_dev''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ne928w73joi"
   },
   "outputs": [],
   "source": [
    "Y_Dev = Y_Dev.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6RFhDW-3jol"
   },
   "outputs": [],
   "source": [
    "Y_Train = Y_Train.values.ravel()\n",
    "Y_Dev = Y_Dev.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to a DMatrix object\n",
    "dtrain = xgb.DMatrix(np.array(X_Train), label=Y_Train)\n",
    "ddev = xgb.DMatrix(np.array(X_Dev), Y_Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the xgboost\n",
    "param = {'max_depth':5, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "#param['nthread'] = 10\n",
    "param['eval_metric'] = 'auc'\n",
    "# Train the model using the training sets\n",
    "num_round = 10\n",
    "mod_xgboost = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= \"%s\\Models\\XGB_base_model.sav\" % cwd\n",
    "pickle.dump(mod_xgboost, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = mod_xgboost.predict(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dev = mod_xgboost.predict(ddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = metrics.roc_auc_score(Y_Train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_score = metrics.roc_auc_score(Y_Dev, pred_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7079486709899623\n",
      "0.6832650199171383\n"
     ]
    }
   ],
   "source": [
    "print(train_score)\n",
    "print(dev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'objective':'binary:logistic','n_jobs':2}\n",
    "clf = xgb.XGBClassifier(**param_dist)\n",
    "clf.mod=clf.fit(X_Train, Y_Train,\n",
    "        eval_set=[(X_Train, Y_Train), (X_Dev, Y_Dev)],\n",
    "        eval_metric='auc',\n",
    "        verbose=False)\n",
    "evals_result = clf.mod.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=2, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
    "       n_jobs=2, nthread=None, objective='binary:logistic',\n",
    "       random_state=1207, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701423\n",
      "0.690246\n"
     ]
    }
   ],
   "source": [
    "pred_train = evals_result['validation_0']['auc'][-1]\n",
    "pred_dev = evals_result['validation_1']['auc'][-1]\n",
    "print(pred_train)\n",
    "print(pred_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7014234721522628\n",
      "0.6902463659005371\n"
     ]
    }
   ],
   "source": [
    "pred_train = clf.mod.predict_proba(X_Train)\n",
    "pred_dev = clf.mod.predict_proba(X_Dev)\n",
    "\n",
    "train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "print(train_score)\n",
    "print(dev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Checking model fit for hyperparamters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100 | learning_rate: 0.001 | Train AUC: 0.6467612175684008 | Dev AUC: 0.6450298208772438\n",
      "n_estimators: 100 | learning_rate: 0.01 | Train AUC: 0.6573948755816859 | Dev AUC: 0.6539861925580803\n",
      "n_estimators: 100 | learning_rate: 0.1 | Train AUC: 0.7014234721522628 | Dev AUC: 0.6902463659005371\n",
      "n_estimators: 100 | learning_rate: 0.2 | Train AUC: 0.7103448336807247 | Dev AUC: 0.6955246128389586\n",
      "n_estimators: 100 | learning_rate: 0.3 | Train AUC: 0.7163073163609537 | Dev AUC: 0.6973363692464791\n",
      "n_estimators: 200 | learning_rate: 0.001 | Train AUC: 0.6507506578597431 | Dev AUC: 0.6482398151717839\n",
      "n_estimators: 200 | learning_rate: 0.01 | Train AUC: 0.669168858908449 | Dev AUC: 0.6649840618197871\n",
      "n_estimators: 200 | learning_rate: 0.1 | Train AUC: 0.7116683750597748 | Dev AUC: 0.6964889904578806\n",
      "n_estimators: 200 | learning_rate: 0.2 | Train AUC: 0.7155025241054742 | Dev AUC: 0.6983791150851262\n",
      "n_estimators: 200 | learning_rate: 0.3 | Train AUC: 0.7163073171749033 | Dev AUC: 0.6973363848380076\n",
      "n_estimators: 300 | learning_rate: 0.001 | Train AUC: 0.6524605999953615 | Dev AUC: 0.6494681209890142\n",
      "n_estimators: 300 | learning_rate: 0.01 | Train AUC: 0.6786195333239106 | Dev AUC: 0.673637890283245\n",
      "n_estimators: 300 | learning_rate: 0.1 | Train AUC: 0.7174528832656413 | Dev AUC: 0.6992345131165814\n",
      "n_estimators: 300 | learning_rate: 0.2 | Train AUC: 0.7155025241054742 | Dev AUC: 0.6983791150851262\n",
      "n_estimators: 300 | learning_rate: 0.3 | Train AUC: 0.7163073173376933 | Dev AUC: 0.6973363848380076\n",
      "n_estimators: 400 | learning_rate: 0.001 | Train AUC: 0.6533689163022164 | Dev AUC: 0.6503403474769632\n",
      "n_estimators: 400 | learning_rate: 0.01 | Train AUC: 0.6850245477015464 | Dev AUC: 0.679381336462172\n",
      "n_estimators: 400 | learning_rate: 0.1 | Train AUC: 0.717452881881927 | Dev AUC: 0.6992345079194051\n",
      "n_estimators: 400 | learning_rate: 0.2 | Train AUC: 0.7155025241054742 | Dev AUC: 0.6983791150851262\n",
      "n_estimators: 400 | learning_rate: 0.3 | Train AUC: 0.7163073173376933 | Dev AUC: 0.6973363848380076\n",
      "n_estimators: 500 | learning_rate: 0.001 | Train AUC: 0.653518575423634 | Dev AUC: 0.6503842168411584\n",
      "n_estimators: 500 | learning_rate: 0.01 | Train AUC: 0.6893298865517722 | Dev AUC: 0.6828842228179111\n",
      "n_estimators: 500 | learning_rate: 0.1 | Train AUC: 0.7174528820447169 | Dev AUC: 0.6992345079194051\n",
      "n_estimators: 500 | learning_rate: 0.2 | Train AUC: 0.7155025241054742 | Dev AUC: 0.6983791150851262\n",
      "n_estimators: 500 | learning_rate: 0.3 | Train AUC: 0.7163073173376933 | Dev AUC: 0.6973363848380076\n",
      "n_estimators: 1000 | learning_rate: 0.001 | Train AUC: 0.6576283498603706 | Dev AUC: 0.6542211620906743\n",
      "n_estimators: 1000 | learning_rate: 0.01 | Train AUC: 0.7010474741598933 | Dev AUC: 0.6903176035945333\n",
      "n_estimators: 1000 | learning_rate: 0.1 | Train AUC: 0.717452881881927 | Dev AUC: 0.6992345079194051\n",
      "n_estimators: 1000 | learning_rate: 0.2 | Train AUC: 0.7155025241054742 | Dev AUC: 0.6983791150851262\n",
      "n_estimators: 1000 | learning_rate: 0.3 | Train AUC: 0.7163073173376933 | Dev AUC: 0.6973363848380076\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 200, 300, 400, 500 , 1000]\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.2 , 0.3]\n",
    "res = []\n",
    "for n in n_estimators:\n",
    "    for l in learning_rate:\n",
    "        param_dist = {'objective':'binary:logistic','random_state':1207,'n_jobs':4}\n",
    "        param_dist['n_estimators'] = n\n",
    "        param_dist['learning_rate'] =l\n",
    "        model = xgb.XGBClassifier(**param_dist)\n",
    "        model = model.fit(X_Train, Y_Train)\n",
    "        pred_train = model.predict_proba(X_Train)\n",
    "        pred_dev = model.predict_proba(X_Dev)\n",
    "        train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "        dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "        res.append([n,l,train_score,dev_score])\n",
    "        print(\"n_estimators: %s | learning_rate: %s | Train AUC: %s | Dev AUC: %s\" % (n,l,train_score,dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.646761</td>\n",
       "      <td>0.645030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.657395</td>\n",
       "      <td>0.653986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.701423</td>\n",
       "      <td>0.690246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.695525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.648240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.669169</td>\n",
       "      <td>0.664984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.711668</td>\n",
       "      <td>0.696489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.652461</td>\n",
       "      <td>0.649468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.678620</td>\n",
       "      <td>0.673638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.653369</td>\n",
       "      <td>0.650340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>400</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.685025</td>\n",
       "      <td>0.679381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>400</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>400</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.653519</td>\n",
       "      <td>0.650384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.689330</td>\n",
       "      <td>0.682884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>500</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.657628</td>\n",
       "      <td>0.654221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.701047</td>\n",
       "      <td>0.690318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  learning_rate  Train_auc_score  Dev_auc_score\n",
       "0            100          0.001         0.646761       0.645030\n",
       "1            100          0.010         0.657395       0.653986\n",
       "2            100          0.100         0.701423       0.690246\n",
       "3            100          0.200         0.710345       0.695525\n",
       "4            100          0.300         0.716307       0.697336\n",
       "5            200          0.001         0.650751       0.648240\n",
       "6            200          0.010         0.669169       0.664984\n",
       "7            200          0.100         0.711668       0.696489\n",
       "8            200          0.200         0.715503       0.698379\n",
       "9            200          0.300         0.716307       0.697336\n",
       "10           300          0.001         0.652461       0.649468\n",
       "11           300          0.010         0.678620       0.673638\n",
       "12           300          0.100         0.717453       0.699235\n",
       "13           300          0.200         0.715503       0.698379\n",
       "14           300          0.300         0.716307       0.697336\n",
       "15           400          0.001         0.653369       0.650340\n",
       "16           400          0.010         0.685025       0.679381\n",
       "17           400          0.100         0.717453       0.699235\n",
       "18           400          0.200         0.715503       0.698379\n",
       "19           400          0.300         0.716307       0.697336\n",
       "20           500          0.001         0.653519       0.650384\n",
       "21           500          0.010         0.689330       0.682884\n",
       "22           500          0.100         0.717453       0.699235\n",
       "23           500          0.200         0.715503       0.698379\n",
       "24           500          0.300         0.716307       0.697336\n",
       "25          1000          0.001         0.657628       0.654221\n",
       "26          1000          0.010         0.701047       0.690318\n",
       "27          1000          0.100         0.717453       0.699235\n",
       "28          1000          0.200         0.715503       0.698379\n",
       "29          1000          0.300         0.716307       0.697336"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res, columns=['n_estimators','learning_rate','Train_auc_score','Dev_auc_score'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['AUC_Diff'] = res['Train_auc_score'] - res['Dev_auc_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "      <th>AUC_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>500</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.017123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.017123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>400</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.017123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.017123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.715503</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.017123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>400</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>500</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.716307</td>\n",
       "      <td>0.697336</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.711668</td>\n",
       "      <td>0.696489</td>\n",
       "      <td>0.015179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.710345</td>\n",
       "      <td>0.695525</td>\n",
       "      <td>0.014820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.701047</td>\n",
       "      <td>0.690318</td>\n",
       "      <td>0.010730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.701423</td>\n",
       "      <td>0.690246</td>\n",
       "      <td>0.011177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>500</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.689330</td>\n",
       "      <td>0.682884</td>\n",
       "      <td>0.006446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>400</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.685025</td>\n",
       "      <td>0.679381</td>\n",
       "      <td>0.005643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.678620</td>\n",
       "      <td>0.673638</td>\n",
       "      <td>0.004982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.669169</td>\n",
       "      <td>0.664984</td>\n",
       "      <td>0.004185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.657628</td>\n",
       "      <td>0.654221</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.657395</td>\n",
       "      <td>0.653986</td>\n",
       "      <td>0.003409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.653519</td>\n",
       "      <td>0.650384</td>\n",
       "      <td>0.003134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.653369</td>\n",
       "      <td>0.650340</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.652461</td>\n",
       "      <td>0.649468</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.650751</td>\n",
       "      <td>0.648240</td>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.646761</td>\n",
       "      <td>0.645030</td>\n",
       "      <td>0.001731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  learning_rate  Train_auc_score  Dev_auc_score  AUC_Diff\n",
       "12           300          0.100         0.717453       0.699235  0.018218\n",
       "22           500          0.100         0.717453       0.699235  0.018218\n",
       "17           400          0.100         0.717453       0.699235  0.018218\n",
       "27          1000          0.100         0.717453       0.699235  0.018218\n",
       "8            200          0.200         0.715503       0.698379  0.017123\n",
       "13           300          0.200         0.715503       0.698379  0.017123\n",
       "18           400          0.200         0.715503       0.698379  0.017123\n",
       "23           500          0.200         0.715503       0.698379  0.017123\n",
       "28          1000          0.200         0.715503       0.698379  0.017123\n",
       "14           300          0.300         0.716307       0.697336  0.018971\n",
       "19           400          0.300         0.716307       0.697336  0.018971\n",
       "24           500          0.300         0.716307       0.697336  0.018971\n",
       "29          1000          0.300         0.716307       0.697336  0.018971\n",
       "9            200          0.300         0.716307       0.697336  0.018971\n",
       "4            100          0.300         0.716307       0.697336  0.018971\n",
       "7            200          0.100         0.711668       0.696489  0.015179\n",
       "3            100          0.200         0.710345       0.695525  0.014820\n",
       "26          1000          0.010         0.701047       0.690318  0.010730\n",
       "2            100          0.100         0.701423       0.690246  0.011177\n",
       "21           500          0.010         0.689330       0.682884  0.006446\n",
       "16           400          0.010         0.685025       0.679381  0.005643\n",
       "11           300          0.010         0.678620       0.673638  0.004982\n",
       "6            200          0.010         0.669169       0.664984  0.004185\n",
       "25          1000          0.001         0.657628       0.654221  0.003407\n",
       "1            100          0.010         0.657395       0.653986  0.003409\n",
       "20           500          0.001         0.653519       0.650384  0.003134\n",
       "15           400          0.001         0.653369       0.650340  0.003029\n",
       "10           300          0.001         0.652461       0.649468  0.002992\n",
       "5            200          0.001         0.650751       0.648240  0.002511\n",
       "0            100          0.001         0.646761       0.645030  0.001731"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values(['Dev_auc_score','AUC_Diff'], ascending=[ 0 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the high dev auc_score with lower difference between train and dev with learning rate =0.1 and n_estimators=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 3 | min_child_weight: 1 | Train AUC: 0.7174528820447169 | Dev AUC: 0.6992345079194051\n",
      "max_depth: 3 | min_child_weight: 2 | Train AUC: 0.7177001013274293 | Dev AUC: 0.6993639124092872\n",
      "max_depth: 3 | min_child_weight: 3 | Train AUC: 0.7174950488662966 | Dev AUC: 0.6996113343760255\n",
      "max_depth: 3 | min_child_weight: 4 | Train AUC: 0.7172194335682343 | Dev AUC: 0.6990800790261822\n",
      "max_depth: 4 | min_child_weight: 1 | Train AUC: 0.7267712678370765 | Dev AUC: 0.7004477938974549\n",
      "max_depth: 4 | min_child_weight: 2 | Train AUC: 0.7268135278558848 | Dev AUC: 0.7003491359018956\n",
      "max_depth: 4 | min_child_weight: 3 | Train AUC: 0.726328119817036 | Dev AUC: 0.7012241688649854\n",
      "max_depth: 4 | min_child_weight: 4 | Train AUC: 0.7257074359600701 | Dev AUC: 0.700979880795488\n",
      "max_depth: 5 | min_child_weight: 1 | Train AUC: 0.7389585144547199 | Dev AUC: 0.7011342421254204\n",
      "max_depth: 5 | min_child_weight: 2 | Train AUC: 0.7380276748602409 | Dev AUC: 0.7014295508735466\n",
      "max_depth: 5 | min_child_weight: 3 | Train AUC: 0.7380567689187638 | Dev AUC: 0.7006816668258735\n",
      "max_depth: 5 | min_child_weight: 4 | Train AUC: 0.7374451425301056 | Dev AUC: 0.7001114950207413\n",
      "max_depth: 6 | min_child_weight: 1 | Train AUC: 0.7550679086506706 | Dev AUC: 0.7004010660863568\n",
      "max_depth: 6 | min_child_weight: 2 | Train AUC: 0.751650743947822 | Dev AUC: 0.7018182996523402\n",
      "max_depth: 6 | min_child_weight: 3 | Train AUC: 0.7533581758628882 | Dev AUC: 0.7010584309163795\n",
      "max_depth: 6 | min_child_weight: 4 | Train AUC: 0.7486425339750655 | Dev AUC: 0.70150154215809\n",
      "max_depth: 8 | min_child_weight: 1 | Train AUC: 0.8013986790359597 | Dev AUC: 0.6993975849138033\n",
      "max_depth: 8 | min_child_weight: 2 | Train AUC: 0.7888086369262075 | Dev AUC: 0.6985614268285927\n",
      "max_depth: 8 | min_child_weight: 3 | Train AUC: 0.7904049744075015 | Dev AUC: 0.7001483949716696\n",
      "max_depth: 8 | min_child_weight: 4 | Train AUC: 0.7852320300789641 | Dev AUC: 0.7003704910988483\n"
     ]
    }
   ],
   "source": [
    "max_depth = [3, 4, 5, 6, 8]\n",
    "min_child_weight = [1, 2, 3, 4]\n",
    "res = []\n",
    "for n in max_depth:\n",
    "    for l in min_child_weight:\n",
    "        param_dist = {'objective':'binary:logistic','random_state':1207,'n_jobs':4,'learning_rate': 0.1,'n_estimators': 500 }\n",
    "        param_dist['max_depth'] = n\n",
    "        param_dist['min_child_weight'] =l\n",
    "        model = xgb.XGBClassifier(**param_dist)\n",
    "        model = model.fit(X_Train, Y_Train)\n",
    "        pred_train = model.predict_proba(X_Train)\n",
    "        pred_dev = model.predict_proba(X_Dev)\n",
    "        train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "        dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "        res.append([n,l,train_score,dev_score])\n",
    "        print(\"max_depth: %s | min_child_weight: %s | Train AUC: %s | Dev AUC: %s\" % (n,l,train_score,dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "      <th>AUC_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.751651</td>\n",
       "      <td>0.701818</td>\n",
       "      <td>0.049832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.748643</td>\n",
       "      <td>0.701502</td>\n",
       "      <td>0.047141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.738028</td>\n",
       "      <td>0.701430</td>\n",
       "      <td>0.036598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.701224</td>\n",
       "      <td>0.025104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.738959</td>\n",
       "      <td>0.701134</td>\n",
       "      <td>0.037824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.753358</td>\n",
       "      <td>0.701058</td>\n",
       "      <td>0.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.725707</td>\n",
       "      <td>0.700980</td>\n",
       "      <td>0.024728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.700682</td>\n",
       "      <td>0.037375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.726771</td>\n",
       "      <td>0.700448</td>\n",
       "      <td>0.026323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755068</td>\n",
       "      <td>0.700401</td>\n",
       "      <td>0.054667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.785232</td>\n",
       "      <td>0.700370</td>\n",
       "      <td>0.084862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.726814</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.026464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.790405</td>\n",
       "      <td>0.700148</td>\n",
       "      <td>0.090257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737445</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>0.037334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.717495</td>\n",
       "      <td>0.699611</td>\n",
       "      <td>0.017884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801399</td>\n",
       "      <td>0.699398</td>\n",
       "      <td>0.102001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.717700</td>\n",
       "      <td>0.699364</td>\n",
       "      <td>0.018336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717453</td>\n",
       "      <td>0.699235</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.717219</td>\n",
       "      <td>0.699080</td>\n",
       "      <td>0.018139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.788809</td>\n",
       "      <td>0.698561</td>\n",
       "      <td>0.090247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_child_weight  Train_auc_score  Dev_auc_score  AUC_Diff\n",
       "13          6                 2         0.751651       0.701818  0.049832\n",
       "15          6                 4         0.748643       0.701502  0.047141\n",
       "9           5                 2         0.738028       0.701430  0.036598\n",
       "6           4                 3         0.726328       0.701224  0.025104\n",
       "8           5                 1         0.738959       0.701134  0.037824\n",
       "14          6                 3         0.753358       0.701058  0.052300\n",
       "7           4                 4         0.725707       0.700980  0.024728\n",
       "10          5                 3         0.738057       0.700682  0.037375\n",
       "4           4                 1         0.726771       0.700448  0.026323\n",
       "12          6                 1         0.755068       0.700401  0.054667\n",
       "19          8                 4         0.785232       0.700370  0.084862\n",
       "5           4                 2         0.726814       0.700349  0.026464\n",
       "18          8                 3         0.790405       0.700148  0.090257\n",
       "11          5                 4         0.737445       0.700111  0.037334\n",
       "2           3                 3         0.717495       0.699611  0.017884\n",
       "16          8                 1         0.801399       0.699398  0.102001\n",
       "1           3                 2         0.717700       0.699364  0.018336\n",
       "0           3                 1         0.717453       0.699235  0.018218\n",
       "3           3                 4         0.717219       0.699080  0.018139\n",
       "17          8                 2         0.788809       0.698561  0.090247"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res, columns=['max_depth','min_child_weight','Train_auc_score','Dev_auc_score'])\n",
    "res['AUC_Diff'] = res['Train_auc_score'] - res['Dev_auc_score']\n",
    "res.sort_values(['Dev_auc_score','AUC_Diff'], ascending=[ 0 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use max_depth =4 and min_child_weight=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0.5 | colsample_bytree: 0.5 | Train AUC: 0.7418425437190841 | Dev AUC: 0.6993762764914362\n",
      "subsample: 0.5 | colsample_bytree: 0.6 | Train AUC: 0.7420923146523832 | Dev AUC: 0.7016399117768948\n",
      "subsample: 0.5 | colsample_bytree: 0.7 | Train AUC: 0.7435249697188652 | Dev AUC: 0.700730936056127\n",
      "subsample: 0.5 | colsample_bytree: 0.8 | Train AUC: 0.7432021031816803 | Dev AUC: 0.7000406055375497\n",
      "subsample: 0.5 | colsample_bytree: 0.9 | Train AUC: 0.7432290384016914 | Dev AUC: 0.7001630146282838\n",
      "subsample: 0.5 | colsample_bytree: 1.0 | Train AUC: 0.7449551046346099 | Dev AUC: 0.7018234760398223\n",
      "subsample: 0.6 | colsample_bytree: 0.5 | Train AUC: 0.7410973109229289 | Dev AUC: 0.7029748064805462\n",
      "subsample: 0.6 | colsample_bytree: 0.6 | Train AUC: 0.7419285077032831 | Dev AUC: 0.7025240605870169\n",
      "subsample: 0.6 | colsample_bytree: 0.7 | Train AUC: 0.7426612132454005 | Dev AUC: 0.7030194918014026\n",
      "subsample: 0.6 | colsample_bytree: 0.8 | Train AUC: 0.743197072403416 | Dev AUC: 0.7023730878159584\n",
      "subsample: 0.6 | colsample_bytree: 0.9 | Train AUC: 0.7413955964265173 | Dev AUC: 0.7039426402216326\n",
      "subsample: 0.6 | colsample_bytree: 1.0 | Train AUC: 0.7420177592298981 | Dev AUC: 0.7030470472295466\n",
      "subsample: 0.7 | colsample_bytree: 0.5 | Train AUC: 0.7419191844804325 | Dev AUC: 0.7034550983206989\n",
      "subsample: 0.7 | colsample_bytree: 0.6 | Train AUC: 0.742305001553746 | Dev AUC: 0.7028465557637775\n",
      "subsample: 0.7 | colsample_bytree: 0.7 | Train AUC: 0.7423024601589242 | Dev AUC: 0.7031915391218997\n",
      "subsample: 0.7 | colsample_bytree: 0.8 | Train AUC: 0.7429968770237041 | Dev AUC: 0.7028081590261074\n",
      "subsample: 0.7 | colsample_bytree: 0.9 | Train AUC: 0.7424566807352694 | Dev AUC: 0.7028584936774792\n",
      "subsample: 0.7 | colsample_bytree: 1.0 | Train AUC: 0.7378683849244206 | Dev AUC: 0.7017385541809256\n",
      "subsample: 0.8 | colsample_bytree: 0.5 | Train AUC: 0.7412382652603984 | Dev AUC: 0.7021337370638387\n",
      "subsample: 0.8 | colsample_bytree: 0.6 | Train AUC: 0.7412041996791416 | Dev AUC: 0.702840537433753\n",
      "subsample: 0.8 | colsample_bytree: 0.7 | Train AUC: 0.7413407923863092 | Dev AUC: 0.7032539208276732\n",
      "subsample: 0.8 | colsample_bytree: 0.8 | Train AUC: 0.7403779365728649 | Dev AUC: 0.7025429627168094\n",
      "subsample: 0.8 | colsample_bytree: 0.9 | Train AUC: 0.7374511129317829 | Dev AUC: 0.7036439948863944\n",
      "subsample: 0.8 | colsample_bytree: 1.0 | Train AUC: 0.7373347642091874 | Dev AUC: 0.70356030995543\n",
      "subsample: 1 | colsample_bytree: 0.5 | Train AUC: 0.7370560581003264 | Dev AUC: 0.7024174197288342\n",
      "subsample: 1 | colsample_bytree: 0.6 | Train AUC: 0.7339977242975355 | Dev AUC: 0.7025952463092513\n",
      "subsample: 1 | colsample_bytree: 0.7 | Train AUC: 0.733171546900151 | Dev AUC: 0.7028629216715906\n",
      "subsample: 1 | colsample_bytree: 0.8 | Train AUC: 0.7319297356650845 | Dev AUC: 0.70239030086349\n",
      "subsample: 1 | colsample_bytree: 0.9 | Train AUC: 0.7280953408066073 | Dev AUC: 0.7012983169776467\n",
      "subsample: 1 | colsample_bytree: 1.0 | Train AUC: 0.726328119817036 | Dev AUC: 0.7012241688649854\n"
     ]
    }
   ],
   "source": [
    "subsample = [i/10.0 for i in range(5,9)]\n",
    "subsample.append(1)\n",
    "colsample_bytree = [i/10.0 for i in range(5,11)]\n",
    "res = []\n",
    "for n in subsample:\n",
    "    for l in colsample_bytree:\n",
    "        param_dist = {'objective':'binary:logistic','random_state':1207,'n_jobs':4,'learning_rate': 0.1,'n_estimators': 500 ,\n",
    "                      'max_depth': 4, 'min_child_weight': 3}\n",
    "        param_dist['subsample'] = n\n",
    "        param_dist['colsample_bytree'] =l\n",
    "        model = xgb.XGBClassifier(**param_dist)\n",
    "        model = model.fit(X_Train, Y_Train)\n",
    "        pred_train = model.predict_proba(X_Train)\n",
    "        pred_dev = model.predict_proba(X_Dev)\n",
    "        train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "        dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "        res.append([n,l,train_score,dev_score])\n",
    "        print(\"subsample: %s | colsample_bytree: %s | Train AUC: %s | Dev AUC: %s\" % (n,l,train_score,dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "      <th>AUC_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.741396</td>\n",
       "      <td>0.703943</td>\n",
       "      <td>0.037453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.737451</td>\n",
       "      <td>0.703644</td>\n",
       "      <td>0.033807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737335</td>\n",
       "      <td>0.703560</td>\n",
       "      <td>0.033774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741919</td>\n",
       "      <td>0.703455</td>\n",
       "      <td>0.038464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.741341</td>\n",
       "      <td>0.703254</td>\n",
       "      <td>0.038087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.742302</td>\n",
       "      <td>0.703192</td>\n",
       "      <td>0.039111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.742018</td>\n",
       "      <td>0.703047</td>\n",
       "      <td>0.038971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.742661</td>\n",
       "      <td>0.703019</td>\n",
       "      <td>0.039642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741097</td>\n",
       "      <td>0.702975</td>\n",
       "      <td>0.038123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.733172</td>\n",
       "      <td>0.702863</td>\n",
       "      <td>0.030309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.742457</td>\n",
       "      <td>0.702858</td>\n",
       "      <td>0.039598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.742305</td>\n",
       "      <td>0.702847</td>\n",
       "      <td>0.039458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.741204</td>\n",
       "      <td>0.702841</td>\n",
       "      <td>0.038364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.742997</td>\n",
       "      <td>0.702808</td>\n",
       "      <td>0.040189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.733998</td>\n",
       "      <td>0.702595</td>\n",
       "      <td>0.031402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.740378</td>\n",
       "      <td>0.702543</td>\n",
       "      <td>0.037835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.741929</td>\n",
       "      <td>0.702524</td>\n",
       "      <td>0.039404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.737056</td>\n",
       "      <td>0.702417</td>\n",
       "      <td>0.034639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.731930</td>\n",
       "      <td>0.702390</td>\n",
       "      <td>0.029539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.743197</td>\n",
       "      <td>0.702373</td>\n",
       "      <td>0.040824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741238</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.039105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744955</td>\n",
       "      <td>0.701823</td>\n",
       "      <td>0.043132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737868</td>\n",
       "      <td>0.701739</td>\n",
       "      <td>0.036130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.742092</td>\n",
       "      <td>0.701640</td>\n",
       "      <td>0.040452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.728095</td>\n",
       "      <td>0.701298</td>\n",
       "      <td>0.026797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726328</td>\n",
       "      <td>0.701224</td>\n",
       "      <td>0.025104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.743525</td>\n",
       "      <td>0.700731</td>\n",
       "      <td>0.042794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.743229</td>\n",
       "      <td>0.700163</td>\n",
       "      <td>0.043066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.743202</td>\n",
       "      <td>0.700041</td>\n",
       "      <td>0.043161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.741843</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.042466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subsample  colsample_bytree  Train_auc_score  Dev_auc_score  AUC_Diff\n",
       "10        0.6               0.9         0.741396       0.703943  0.037453\n",
       "22        0.8               0.9         0.737451       0.703644  0.033807\n",
       "23        0.8               1.0         0.737335       0.703560  0.033774\n",
       "12        0.7               0.5         0.741919       0.703455  0.038464\n",
       "20        0.8               0.7         0.741341       0.703254  0.038087\n",
       "14        0.7               0.7         0.742302       0.703192  0.039111\n",
       "11        0.6               1.0         0.742018       0.703047  0.038971\n",
       "8         0.6               0.7         0.742661       0.703019  0.039642\n",
       "6         0.6               0.5         0.741097       0.702975  0.038123\n",
       "26        1.0               0.7         0.733172       0.702863  0.030309\n",
       "16        0.7               0.9         0.742457       0.702858  0.039598\n",
       "13        0.7               0.6         0.742305       0.702847  0.039458\n",
       "19        0.8               0.6         0.741204       0.702841  0.038364\n",
       "15        0.7               0.8         0.742997       0.702808  0.040189\n",
       "25        1.0               0.6         0.733998       0.702595  0.031402\n",
       "21        0.8               0.8         0.740378       0.702543  0.037835\n",
       "7         0.6               0.6         0.741929       0.702524  0.039404\n",
       "24        1.0               0.5         0.737056       0.702417  0.034639\n",
       "27        1.0               0.8         0.731930       0.702390  0.029539\n",
       "9         0.6               0.8         0.743197       0.702373  0.040824\n",
       "18        0.8               0.5         0.741238       0.702134  0.039105\n",
       "5         0.5               1.0         0.744955       0.701823  0.043132\n",
       "17        0.7               1.0         0.737868       0.701739  0.036130\n",
       "1         0.5               0.6         0.742092       0.701640  0.040452\n",
       "28        1.0               0.9         0.728095       0.701298  0.026797\n",
       "29        1.0               1.0         0.726328       0.701224  0.025104\n",
       "2         0.5               0.7         0.743525       0.700731  0.042794\n",
       "4         0.5               0.9         0.743229       0.700163  0.043066\n",
       "3         0.5               0.8         0.743202       0.700041  0.043161\n",
       "0         0.5               0.5         0.741843       0.699376  0.042466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res, columns=['subsample','colsample_bytree','Train_auc_score','Dev_auc_score'])\n",
    "res['AUC_Diff'] = res['Train_auc_score'] - res['Dev_auc_score']\n",
    "res.sort_values(['Dev_auc_score','AUC_Diff'], ascending=[ 0 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use subsample =0.8 and colsample_bytree=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune gamma parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0 | Train AUC: 0.7373347642091874 | Dev AUC: 0.70356030995543\n",
      "gamma: 0.1 | Train AUC: 0.7378661287375372 | Dev AUC: 0.7036145892635278\n",
      "gamma: 0.2 | Train AUC: 0.7379012938833023 | Dev AUC: 0.7041575954287301\n",
      "gamma: 0.5 | Train AUC: 0.7374418932433209 | Dev AUC: 0.7026681938742132\n",
      "gamma: 1 | Train AUC: 0.7377922843814186 | Dev AUC: 0.7028797241422036\n",
      "gamma: 5 | Train AUC: 0.7349401590923706 | Dev AUC: 0.7028547724993293\n",
      "gamma: 10 | Train AUC: 0.7264385214983076 | Dev AUC: 0.7018289226804665\n"
     ]
    }
   ],
   "source": [
    "gamma = [0, 0.1, 0.2, 0.5, 1, 5, 10]\n",
    "res = []\n",
    "for n in gamma:\n",
    "    param_dist = {'objective':'binary:logistic','random_state':1207,'n_jobs':4,'learning_rate': 0.1,'n_estimators': 500 ,\n",
    "                  'max_depth': 4, 'min_child_weight': 3,'colsample_bytree': 1, 'subsample': 0.8 ,\n",
    "                  'reg_lambda': 1 ,'reg_alpha': 0}\n",
    "    param_dist['gamma'] = n\n",
    "    model = xgb.XGBClassifier(**param_dist)\n",
    "    model = model.fit(X_Train, Y_Train)\n",
    "    pred_train = model.predict_proba(X_Train)\n",
    "    pred_dev = model.predict_proba(X_Dev)\n",
    "    train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "    dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "    res.append([n,train_score,dev_score])\n",
    "    print(\"gamma: %s | Train AUC: %s | Dev AUC: %s\" % (n,train_score,dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "      <th>AUC_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.737901</td>\n",
       "      <td>0.704158</td>\n",
       "      <td>0.033744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.737866</td>\n",
       "      <td>0.703615</td>\n",
       "      <td>0.034252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737335</td>\n",
       "      <td>0.703560</td>\n",
       "      <td>0.033774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.737792</td>\n",
       "      <td>0.702880</td>\n",
       "      <td>0.034913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.702855</td>\n",
       "      <td>0.032085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.737442</td>\n",
       "      <td>0.702668</td>\n",
       "      <td>0.034774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.726439</td>\n",
       "      <td>0.701829</td>\n",
       "      <td>0.024610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gamma  Train_auc_score  Dev_auc_score  AUC_Diff\n",
       "2    0.2         0.737901       0.704158  0.033744\n",
       "1    0.1         0.737866       0.703615  0.034252\n",
       "0    0.0         0.737335       0.703560  0.033774\n",
       "4    1.0         0.737792       0.702880  0.034913\n",
       "5    5.0         0.734940       0.702855  0.032085\n",
       "3    0.5         0.737442       0.702668  0.034774\n",
       "6   10.0         0.726439       0.701829  0.024610"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res, columns=['gamma','Train_auc_score','Dev_auc_score'])\n",
    "res['AUC_Diff'] = res['Train_auc_score'] - res['Dev_auc_score']\n",
    "res.sort_values(['Dev_auc_score','AUC_Diff'], ascending=[ 0 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got good result with gamma = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune alpha - regularization L1 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_alpha: 0.0001 | Train AUC: 0.7378486057864625 | Dev AUC: 0.7035861139351989\n",
      "reg_alpha: 0.01 | Train AUC: 0.738218678307172 | Dev AUC: 0.7030123820643787\n",
      "reg_alpha: 0.1 | Train AUC: 0.7365220116080597 | Dev AUC: 0.702627182956921\n",
      "reg_alpha: 0 | Train AUC: 0.7373347642091874 | Dev AUC: 0.70356030995543\n",
      "reg_alpha: 1 | Train AUC: 0.7404854157681141 | Dev AUC: 0.7035168771540345\n",
      "reg_alpha: 5 | Train AUC: 0.7440620472780302 | Dev AUC: 0.7035801631684648\n",
      "reg_alpha: 10 | Train AUC: 0.7409452491850955 | Dev AUC: 0.7035625447411906\n"
     ]
    }
   ],
   "source": [
    "reg_alpha = [1e-4, 1e-2, 0.1,0, 1, 5, 10]\n",
    "res = []\n",
    "for n in reg_alpha:\n",
    "    param_dist = {'objective':'binary:logistic','random_state':1207,'n_jobs':4,'learning_rate': 0.1,'n_estimators': 500 ,\n",
    "                  'max_depth': 4, 'min_child_weight': 3,'colsample_bytree': 1, 'subsample': 0.8}\n",
    "    param_dist['reg_alpha'] = n\n",
    "    model = xgb.XGBClassifier(**param_dist)\n",
    "    model = model.fit(X_Train, Y_Train)\n",
    "    pred_train = model.predict_proba(X_Train)\n",
    "    pred_dev = model.predict_proba(X_Dev)\n",
    "    train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "    dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "    res.append([n,train_score,dev_score])\n",
    "    print(\"reg_alpha: %s | Train AUC: %s | Dev AUC: %s\" % (n,train_score,dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "      <th>AUC_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.737849</td>\n",
       "      <td>0.703586</td>\n",
       "      <td>0.034262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.744062</td>\n",
       "      <td>0.703580</td>\n",
       "      <td>0.040482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.740945</td>\n",
       "      <td>0.703563</td>\n",
       "      <td>0.037383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.737335</td>\n",
       "      <td>0.703560</td>\n",
       "      <td>0.033774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.740485</td>\n",
       "      <td>0.703517</td>\n",
       "      <td>0.036969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.738219</td>\n",
       "      <td>0.703012</td>\n",
       "      <td>0.035206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.736522</td>\n",
       "      <td>0.702627</td>\n",
       "      <td>0.033895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_alpha  Train_auc_score  Dev_auc_score  AUC_Diff\n",
       "0     0.0001         0.737849       0.703586  0.034262\n",
       "5     5.0000         0.744062       0.703580  0.040482\n",
       "6    10.0000         0.740945       0.703563  0.037383\n",
       "3     0.0000         0.737335       0.703560  0.033774\n",
       "4     1.0000         0.740485       0.703517  0.036969\n",
       "1     0.0100         0.738219       0.703012  0.035206\n",
       "2     0.1000         0.736522       0.702627  0.033895"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res, columns=['reg_alpha','Train_auc_score','Dev_auc_score'])\n",
    "res['AUC_Diff'] = res['Train_auc_score'] - res['Dev_auc_score']\n",
    "res.sort_values(['Dev_auc_score','AUC_Diff'], ascending=[ 0 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prefer to choose reg_alpha = 0 because it has the lowest auc difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune lambda - regularization L2 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_lambda: 0.0001 | Train AUC: 0.7372938104980846 | Dev AUC: 0.702714724192616\n",
      "reg_lambda: 0.01 | Train AUC: 0.7378978664229511 | Dev AUC: 0.7034886512901626\n",
      "reg_lambda: 0.1 | Train AUC: 0.7385175943775122 | Dev AUC: 0.7040308518930558\n",
      "reg_lambda: 1 | Train AUC: 0.7373347642091874 | Dev AUC: 0.70356030995543\n",
      "reg_lambda: 5 | Train AUC: 0.737424752767161 | Dev AUC: 0.7034380048082196\n",
      "reg_lambda: 10 | Train AUC: 0.7384589330301714 | Dev AUC: 0.7036590303171036\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = [1e-4, 1e-2, 0.1, 1, 5, 10]\n",
    "res = []\n",
    "for n in reg_lambda:\n",
    "    param_dist = {'objective':'binary:logistic','random_state':1207,'n_jobs':4,'learning_rate': 0.1,'n_estimators': 500 ,\n",
    "                  'max_depth': 4, 'min_child_weight': 3,'colsample_bytree': 1, 'subsample': 0.8}\n",
    "    param_dist['reg_lambda'] = n\n",
    "    model = xgb.XGBClassifier(**param_dist)\n",
    "    model = model.fit(X_Train, Y_Train)\n",
    "    pred_train = model.predict_proba(X_Train)\n",
    "    pred_dev = model.predict_proba(X_Dev)\n",
    "    train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "    dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "    res.append([n,train_score,dev_score])\n",
    "    print(\"reg_lambda: %s | Train AUC: %s | Dev AUC: %s\" % (n,train_score,dev_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>Train_auc_score</th>\n",
       "      <th>Dev_auc_score</th>\n",
       "      <th>AUC_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.738518</td>\n",
       "      <td>0.704031</td>\n",
       "      <td>0.034487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.738459</td>\n",
       "      <td>0.703659</td>\n",
       "      <td>0.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.737335</td>\n",
       "      <td>0.703560</td>\n",
       "      <td>0.033774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.737898</td>\n",
       "      <td>0.703489</td>\n",
       "      <td>0.034409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>0.737425</td>\n",
       "      <td>0.703438</td>\n",
       "      <td>0.033987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.737294</td>\n",
       "      <td>0.702715</td>\n",
       "      <td>0.034579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_lambda  Train_auc_score  Dev_auc_score  AUC_Diff\n",
       "2      0.1000         0.738518       0.704031  0.034487\n",
       "5     10.0000         0.738459       0.703659  0.034800\n",
       "3      1.0000         0.737335       0.703560  0.033774\n",
       "1      0.0100         0.737898       0.703489  0.034409\n",
       "4      5.0000         0.737425       0.703438  0.033987\n",
       "0      0.0001         0.737294       0.702715  0.034579"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res, columns=['reg_lambda','Train_auc_score','Dev_auc_score'])\n",
    "res['AUC_Diff'] = res['Train_auc_score'] - res['Dev_auc_score']\n",
    "res.sort_values(['Dev_auc_score','AUC_Diff'], ascending=[ 0 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prefer to choose reg_lambda = 1 because it has the lowest auc difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the tuned parameters into final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.1,  \n",
    "                      colsample_bytree = 1,\n",
    "                      subsample = 0.8,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=500, \n",
    "                      max_depth=4, \n",
    "                      reg_lambda=1,\n",
    "                      reg_alpha=0,\n",
    "                     gamma=0.2,\n",
    "                      min_child_weight=3,\n",
    "                      random_state=1207,n_jobs=4)\n",
    "clf.mod=clf.fit(X_Train, Y_Train,\n",
    "        eval_set=[(X_Train, Y_Train), (X_Dev, Y_Dev)],\n",
    "        eval_metric='auc',\n",
    "        verbose=False)\n",
    "evals_result = clf.mod.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.2, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=3, missing=None, n_estimators=500,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       random_state=1207, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7379012938833023\n",
      "0.7041575954287301\n"
     ]
    }
   ],
   "source": [
    "pred_train = clf.mod.predict_proba(X_Train)\n",
    "pred_dev = clf.mod.predict_proba(X_Dev)\n",
    "\n",
    "train_score = metrics.roc_auc_score(Y_Train, pred_train[:,1])\n",
    "dev_score = metrics.roc_auc_score(Y_Dev, pred_dev[:,1])\n",
    "print(train_score)\n",
    "print(dev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check for Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fop, mpv = calibration_curve(Y_Dev, pred_dev[:,1], n_bins=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot model reliability\n",
    "pyplot.plot(mpv, fop, marker='.')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1361149630695373"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Y_Dev,  pred_dev[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the model\n",
    "filename= \"%s\\Models\\XGB_best_model.sav\" % cwd\n",
    "pickle.dump(clf.mod, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
